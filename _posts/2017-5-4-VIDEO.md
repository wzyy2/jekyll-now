---
layout: post
title: Multimedia User Guide(Rockchip Linux)
category: [media]
tag: [CN]
---

# Overall

这里主要记录一些月经问题, 主要帮助通过gstreamer来在rockchip平台上做multimedia的开发.

首先介绍rockchip平台上视频编解码大概的流程

```
 vpu_service  -->  mpp --> gstreamer/ffmpeg --> app
```

* vpu_service: 驱动
* mpp: rockchip平台的视频编解码中间件
* gstreamer/ffmpeg: 对接app的组件


目前rockchip提供的完整solution是基于gstreamer的，使用gstreamer的好处就是可以比较方便的基于pipeline的方式完整播放器， 编码器这些应用。
对gstreamer不了解的话，也可以看看博客里关于gstreamer的文章。

直接用使用底层的api, 比如通过mpp完成编解码，也可以。但先提醒，复杂应用下会很麻烦，因为你需要直接接触很多底层的概念，并不是很想支持。。。
当然如果只是简单的输入码流，输出画面， 是可以的。

## Note
Multimedia和Graphic在实际应用中是密不可分的，所以要用好media，一定要先了解清楚graphic。关于graphic，
可以搜博客里的另一篇Graphic user guide。

自己下载编译代码，请一定要注意版本（可以在commit log或者文件名里看）。我们现在github的代码推送是滚动的，但是我们放在yocto和debian里相关组件的版本都是固定的，随便切取版本不一定能使用。

另外你要很好的理解这块内容，最好接触下下面的概念：
`v4l2,dmabuf,gstreamer,drm,opengles,gbm`
这块的开发，其实都是很灵活的，如果你足够了解这些基础的东西，很容易利用已有的软件做各种组合，如果你不了解的话，能做的事情就不多了。
主要在rockchip linux平台上，主要的关键还是`dmabuf`，我们所有的graphic和media，都是基于`dmabuf`来达到`zero-copy`，和你过去接触的`fb`，`mmap`的方式会有很大的不一样。


# Gstreamer-1.0
Rockchip have provide two gstreamer plugin packages:
* [gstreamer-rockchip](https://github.com/rockchip-linux/gstreamer-rockchip)
* [gstreamer-rockchip-extra](https://github.com/rockchip-linux/gstreamer-rockchip-extra)

`(Note: gstreamer-rockchip source for debian is pushed to [my personal github](https://github.com/wzyy2/gstreamer-rockchip/tree/debian-20170811).`

gstreamer-rockchip includes the following video decoders and encoders:

| Elements       | Type  |  Comments  | 
| :----:  | :----:  | :----:  | 
| mppvideodec    | Video Decoder | h264, h265, jpeg, vp8, vp9 |
| mpph264enc        |   Video Encoder    | h264   | 


gstreamer-rockchip-extra includes the following plugins:<br>
please refer to [gstreamer-rockchip-extra README](https://github.com/rockchip-linux/gstreamer-rockchip) on github for more infos.

| Elements       | Type  |  Comments  | 
| :----:  | :----:  | :----:  | 
| rkximagesink    | Video Render (sink) |  kmssink + ximagesink |
| kmssink        |   Video Render (sink)   | overlay display   | 
| rgaconvert       |    Video Converter   | video colorspace,format,size conversion  | 
| rkcamsrc        |    Device Sources  |  rockchip isp camera source  | 


## Pipeline Example

See: <br>
https://github.com/rockchip-linux/rk-rootfs-build/tree/master/overlay-debug/usr/local

Decode with uridecodebin/playbin:
```
gst-launch-1.0 uridecodebin uri=file:///usr/local/test.mp4  ! kmssink
```

Decode (JPEG):
```
gst-launch-1.0 -v videotestsrc  ! "video/x-raw,width=1920,height=1080"  ! queue ! jpegenc ! queue ! jpegparse ! queue ! mppvideodec ! kmssink 
```

Encode:
```
gst-launch-1.0 videotestsrc num-buffers=512 ! video/x-raw,format=NV12,width=1920,height= 1080,framerate=30/1 \
    ! queue ! mpph264enc ! queue ! h264parse ! mpegtsmux ! filesink location=/home/linaro/2k.ts
```

MIPI Camera:
```
gst-launch-1.0 rkcamsrc device=/dev/video0 io-mode=4 disable-3A=true ! videoconvert ! video/x-raw,format=NV12,width=640,height=480  ! kmssink
```

CIF Camera/USB Camera:
```
gst-launch-1.0 v4l2src device=/dev/video0 ! mppvideodec ! kmssink
```

RGA Convert:
```
gst-launch-1.0 -v videotestsrc ! "video/x-raw,format=BGRA, width=1920,height=1080,framerate=30/1" ! \
 rgaconvert hflip=false vflip=false rotation=90 input-crop=0x0x1920x1080 output-crop=0x0x640x360 \
 output-io-mode=dmabuf capture-io-mode=dmabuf ! \
 "video/x-raw,format=NV12, width=640,height=640x360,framerate=30/1" ! kmssink
```

## Usage

使用的gstreamer的时候，如果你的应用只是要发起一个编码或者解码过程，那直接参考gst-lauch，集成到应用皆可。
其工作方式就类似于在应用里每次输入一次命令一样

### Player
如果是要做player，最好是使用qtmultimedia来做，qtmultimedia可以直接调用到gstreamer。不过要注意qtmultiemdia还涉及到显示问题，
请参考下面的`Playback with QT multiemdia is slow`。
或者debian下`/usr/local/bin/test_dec-qt.sh`脚本。

关于qt，还有一个很有意思的就是，总是有人问debian上怎么用，怎么编译。
我的建议是，如果你对这些东西一翘不通，那么打开我们[yocto的wiki](http://opensource.rock-chips.com/wiki_Yocto)，点击去qt,好好按文档过一次，你就有一个qt的工作环境了，不要嫌麻烦找麻烦； 如果你是一定要在debian上用，那么google qt的资料，好好过一遍，也很快的。
等我们同事的回复，是最无语的。。。

### 自己管理Buffer
如果你的应用需要深度化的控制，自己管理buffer，而不是仅仅是在pipeline上开关， 那么可以参考博客里的另一篇gstreamer+opencv。

# [Mpp](https://github.com/rockchip-linux/gstreamer-rockchip)

`(Note: gstreamer-rockchip source for debian is pushed to [my personal github](https://github.com/wzyy2/mpp/tree/debian-20170811)` 

直接使用mpp的例子请看代码下的`test/mpi_dec_test`。

更多的文档可以看mpp下readme。

# FFMpeg

虽然ffmpeg从3.4以后就合并了mpp支持,但是除非你很了解这些，不然不推荐使用，请不要觉得xxx app使用的ffmpeg，我替换一个可以调的mpp的ffmpeg就可以工作了，这里涉及到一个format和zero-copy的问题。

ffmpeg配套的测试播放器可以用mpv， 不过mpv关于drm的部分暂时还没有合并，可以关注下，如果合并了，直接拉官方的代码就可以。

mpv和ffmpeg的代码：<br>
https://github.com/rockchip-linux/meta-rockchip/commit/bc7d2db0aaefdafaf73fd264ada6be2b93146d41

# Device Driver

## VPU

rk的私有驱动, 一般不需要有接触, 使用mpp既可.  
驱动的位置在drvier/video/rockchip下面， 有很多vpu_service, mpp_service一类的， 主要对应不同版本的驱动， 不用细究， sdk给出来什么就用什么。

## RGA

Source:<br>
https://github.com/rockchip-linux/kernel/tree/release-4.4/drivers/media/platform/rockchip-rga

关键词： v4l2 m2m  
Demo: https://github.com/wzyy2/rga-v4l2-demo

rga linux版本的驱动是根据v4l2 m2m的api写出来, 如果需要直接操作v4l2 device, 最好是参考驱动里的rga.c和v4l2 m2m的userspace demo, 
目前我们并没有提供任何的wrap lib.

# FAQ

#### I have use mppvideodec/mppvideoenc, however, it is slow.
检查下你是不是用了videoconvert, 如果使用了videoconvert, 如果用了, 那CPU会参与进去转颜色格式, 导致性能下降.
还有检查下你使用的sink, 想xvimagesink这种, 也是CPU直接拷贝的, 速度会很慢的. 可以的话尽量使用glimagesink, wayland(gpu)和kmssink, rkximagesink(drm).
其中drm的性能最好.另外要注意使用gpu的话, 在x11上有稍微的性能缺陷.

如果你一定要用autovideosink, 那么可以下面的补丁强制mppvideodec输出到rkximagesink上:<br>
https://github.com/wzyy2/gstreamer-rockchip/commit/6c4672a69fe4fc0aa08853825fb39014a26a8746

背景知识: 图像和视频这种的Buffer, 一般为了DMA coherent, 都是uncached, 这种情况下, 如果CPU要操作, 那耗时是很大的.

#### Playback with QT multiemdia is slow
同上, 需要指定sink, 具体的方法根据display backend不同而不同, 见:<br>
https://github.com/rockchip-linux/meta-rockchip-extra/tree/master/recipes-rk/autostart/autostart

#### How to build
Debian的使用[docker](https://github.com/rockchip-linux/docker-rockchip), yocto的话本身就是编译工具.
或者你自己想法办法, 这个不是一个应该问的问题.

#### 如何多路合成

多路合成可以通过rga设置好crop，把所有的影片copy到一个buffer上去，但是这个目前通过gstreamer还没有办法做。<br>
一个可行的办法是用通过3.4以上版本ffmpeg调用mpp解码，得到含有drm_prime的frame，取出dmabuf，通过v4l2的ioctl操作rga，把取出合成到目标buffer上。目标buffer可以通过drm申请，显示也可以通过drm显示。<br>
这个主要的问题是没有写demo，所以需要user根据前面的`rga-v4l2-demo`和网络上的ffmpeg+mpp资料（可以看看mpv上drm vo，那个就是用的drm_prime)自己根据理解研究出来。<br>
带mpp ffmpeg的环境可以用yocto弄出来。<br>
还是得提醒，不要嫌麻烦然后给自己找麻烦。。该怎么做，就先按已有的资料一步步做。
